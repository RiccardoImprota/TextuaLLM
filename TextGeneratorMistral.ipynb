{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=600\n",
    "model='mistral'\n",
    "topic='misinformation_health'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mistralAPI():\n",
    "\n",
    "  # Point to the local server\n",
    "  client = OpenAI(base_url=\"http://localhost:1234/v1\", api_key=\"not-needed\")\n",
    "\n",
    "  completion = client.chat.completions.create(\n",
    "    model=\"local-model\", # this field is currently unused\n",
    "    messages=[\n",
    "      #{\"role\": \"system\", \"content\": \"Di seguito Ã¨ riportata un'istruzione che descrive un compito. Scrivi una risposta appropriata alla richiesta\"},\n",
    "      {\"role\": \"system\", \"content\": \"Below is an instruction that describes a task. Write a response that appropriately completes the request.\"},\n",
    "      #{\"role\": \"user\", \"content\": f\"\"\"Cosa ne pensi delle bufale e delle teorie del complotto riguardo la Salute? Struttura la risposta in base alle tue convinzioni e non aver paura di dire le cose come stanno. Massimizza la lunghezza della risposta.\"\"\"}\n",
    "      {\"role\": \"user\", \"content\": f\"\"\" What do you think about the topic of misinformation and conspiracy theories in Health? Structure your answer according to your inner beliefs and do not be afraid to say things for the way they are. Maximise the length of the reply.\"\"\"}\n",
    "    ],\n",
    "    max_tokens= 1000,\n",
    "    temperature=0.5,\n",
    "  )\n",
    "\n",
    "  return completion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mistral_data = []\n",
    "\n",
    "for i in range(n):\n",
    "    if i<50:\n",
    "        print(i)\n",
    "    \n",
    "    if i % 100 == 0:\n",
    "        print(f\"iter: {i}\")\n",
    "\n",
    "    completion = mistralAPI()  \n",
    "    text_to_append = completion.choices[0].message.content\n",
    "    mistral_data.append(text_to_append)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the data to a JSON file\n",
    "with open(f'texts/{n}_{topic}_{model}.json', 'w') as json_file:\n",
    "    json.dump(mistral_data, json_file,indent=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(mistral_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mistral_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from pprint import pprint\n",
    "#pprint(mistral_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TFMN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
