{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Define the request template\n",
    "def create_request(custom_id, prompt):\n",
    "    return {\n",
    "        \"custom_id\": custom_id,\n",
    "        \"method\": \"POST\",\n",
    "        \"url\": \"/v1/chat/completions\",\n",
    "        \"body\": {\n",
    "            \"model\": \"gpt-4o\",\n",
    "            \"messages\": [\n",
    "                {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            \"max_tokens\": 1000\n",
    "        }\n",
    "    }\n",
    "\n",
    "# Generate 100 requests\n",
    "requests = []\n",
    "for i in range(1, 101):\n",
    "    custom_id = f\"request-{i}\"\n",
    "    prompt = f\"What do you think about the topic of Climate Change? Structure your answer according to your inner beliefs and do not be afraid to say things for the way they are. Maximise the length of the reply.\"\n",
    "    request = create_request(custom_id, prompt)\n",
    "    requests.append(request)\n",
    "\n",
    "# Write requests to a JSONL file\n",
    "with open(\"batch_climate_GPT4_requests.jsonl\", \"w\") as file:\n",
    "    for request in requests:\n",
    "        file.write(json.dumps(request) + \"\\n\")\n",
    "\n",
    "print(\"Batch requests have been written to batch_requests.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI(\n",
    "  api_key= '',\n",
    "  organization=''\n",
    ")\n",
    "\n",
    "batch_input_file = client.files.create(\n",
    "  file=open(\"batch_climate_GPT4_requests.jsonl\", \"rb\"),\n",
    "  purpose=\"batch\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_input_file_id = batch_input_file.id\n",
    "print(\"Batch input file created with ID:\", batch_input_file_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.batches.create(\n",
    "    input_file_id=batch_input_file_id,\n",
    "    endpoint=\"/v1/chat/completions\",\n",
    "    completion_window=\"24h\",\n",
    "    metadata={\n",
    "      \"description\": \"first test batch API climate\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.batches.retrieve(\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_response = client.files.content(\"\")\n",
    "print(file_response.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"batch_output.jsonl\", \"w\") as file:\n",
    "    file.write(file_response.text)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "emoatlas_ennemesino",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
