{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from emoatlas import EmoScores\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from pprint import pprint\n",
    "from emoatlas.resources import _valences\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from math import sqrt\n",
    "\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "\n",
    "emos=EmoScores()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_output_dir = \"Valence_Metrics\"\n",
    "true_dir = \"localdb\"\n",
    "\n",
    "captiondictionary={'climate':'Climate Change',\n",
    "                       'gwarming':'Global warming',\n",
    "                       'math': 'Math anxiety',\n",
    "                       'misinformation_health': 'Misinformation in health'}\n",
    "\n",
    "folders_of_interest = ['climate', 'math', 'misinformation_health','gwarming']\n",
    "folders_of_interest = ['misinformation_health']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_model(filename):\n",
    "    match = re.search(r'_(.*?)_', filename)\n",
    "    if match:\n",
    "        return match.group(1)\n",
    "    return None\n",
    "\n",
    "def get_valence_sets(weighted_fmnt, language='english'):\n",
    "    \n",
    "    positive, negative, ambivalent = _valences(language)\n",
    "\n",
    "    all_nodes = set(node for edge in weighted_fmnt for node in edge[:2])\n",
    "\n",
    "    positive_nodes = all_nodes.intersection(positive)\n",
    "    negative_nodes = all_nodes.intersection(negative)\n",
    "    neutral_nodes = all_nodes - (positive_nodes | negative_nodes )\n",
    "\n",
    "    return positive_nodes, negative_nodes, neutral_nodes\n",
    "\n",
    "def get_true_scores(weighted_fmnt,language='english',get_percentage=True):    \n",
    "    positive, negative, neutral = get_valence_sets(weighted_fmnt, language=language)\n",
    "\n",
    "\n",
    "    def get_valence(word):\n",
    "        if word in positive:\n",
    "            return 'positive'\n",
    "        elif word in negative:\n",
    "            return 'negative'\n",
    "        else:\n",
    "            return 'neutral'\n",
    "    \n",
    "    # Weighted network analysis\n",
    "    weights = {\n",
    "        'pos_pos': 0 , 'neg_neg': 0, 'pos_neg': 0\n",
    "                    }\n",
    "        \n",
    "    for node1, node2, weight in weighted_fmnt:\n",
    "        valence1, valence2 = get_valence(node1), get_valence(node2)\n",
    "    \n",
    "        # Random distribution\n",
    "        if valence1 == 'positive' and valence2 == 'positive':\n",
    "            weights['pos_pos'] += 1\n",
    "        elif valence1 == 'negative' and valence2 == 'negative':\n",
    "            weights['neg_neg'] += 1\n",
    "        elif (valence1 == 'negative' and valence2 == 'positive') or (valence1 == 'positive' and valence2 == 'negative'):\n",
    "            weights['pos_neg'] += 1\n",
    "\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_valence_scores= {}\n",
    "\n",
    "for folder in folders_of_interest:\n",
    "    true_folder_path = os.path.join(true_dir, folder)\n",
    "\n",
    "    for filename in os.listdir(true_folder_path):\n",
    "      true_path = os.path.join(true_folder_path, filename)\n",
    "      with open(true_path, 'r') as file:\n",
    "\n",
    "       fmnts=[]\n",
    "       for line in file:\n",
    "          data = json.loads(line)\n",
    "          fmnts.append(data['fmnt']['syntactic'])\n",
    "\n",
    "      \n",
    "      w_fmnt = emos.combine_edgelists(fmnts)\n",
    "      \n",
    "      if ('ITA') in filename:\n",
    "         true_valence_scores[filename.rstrip('.jsonl')] = get_true_scores(w_fmnt,language='italian')\n",
    "      else:\n",
    "         true_valence_scores[filename.rstrip('.jsonl')] = get_true_scores(w_fmnt,language='english')\n",
    "\n",
    "pprint(true_valence_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_valence_scores={}\n",
    "\n",
    "for folder in folders_of_interest:\n",
    "    random_folder_path = os.path.join(base_output_dir, folder)\n",
    "\n",
    "    for filename in os.listdir(random_folder_path):\n",
    "        file_path = os.path.join(random_folder_path, filename)\n",
    "\n",
    "        with open(file_path, 'r') as file:\n",
    "            fmnts=[]\n",
    "            for line in file:\n",
    "                data = json.loads(line)\n",
    "                fmnts.append((data['pos_pos'],data['pos_neg'],data['neg_neg']))\n",
    "            random_valence_scores[filename.rstrip('_valences.jsonl')] = fmnts\n",
    "\n",
    "pprint(random_valence_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_stats(data):\n",
    "    mean = np.mean(data)\n",
    "    std = np.std(data, ddof=1)\n",
    "    n = len(data)\n",
    "    # Calculate the standard error of the mean\n",
    "    sem = std / np.sqrt(n)\n",
    "    print(mean,std,n)\n",
    "     # Z-value for 95% confidence\n",
    "    z_value = 1.96\n",
    "    # Calculate margin of error\n",
    "    margin_of_error = z_value * (std / sqrt(n))\n",
    "\n",
    "    # Calculate confidence interval\n",
    "    ci = (mean - margin_of_error, mean + margin_of_error)\n",
    "    # Calculate the confidence interval using the t-distribution\n",
    "    ci = stats.t.interval(confidence=0.95, df=n-1, loc=mean,scale=sem)\n",
    "\n",
    "    # Calculate the 2.5th and 97.5th percentiles for the confidence interval\n",
    "    lower_bound = np.percentile(data, 2.5)\n",
    "    upper_bound = np.percentile(data, 97.5)\n",
    "\n",
    "    # Confidence interval based on percentiles\n",
    "    ci = (lower_bound, upper_bound)\n",
    "    print(ci)\n",
    "    return mean, std, ci\n",
    "\n",
    "# Calcola le statistiche per i valori casuali\n",
    "random_stats = {}\n",
    "for model in random_valence_scores:\n",
    "    random_stats[model] = {\n",
    "        'pos_pos': calculate_stats([t[0] for t in random_valence_scores[model]]),\n",
    "        'pos_neg': calculate_stats([t[1] for t in random_valence_scores[model]]),\n",
    "        'neg_neg': calculate_stats([t[2] for t in random_valence_scores[model]])\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_average_tuples(data):\n",
    "    result = {}\n",
    "    for model, tuples in data.items():\n",
    "        sum_pos_pos = sum(t[0] for t in tuples)\n",
    "        sum_pos_neg = sum(t[1] for t in tuples)\n",
    "        sum_neg_neg = sum(t[2] for t in tuples)\n",
    "        count = len(tuples)\n",
    "        \n",
    "        result[model] = {\n",
    "            'pos_pos': round(sum_pos_pos / count),\n",
    "            'pos_neg': round(sum_pos_neg / count),\n",
    "            'neg_neg': round(sum_neg_neg / count)\n",
    "        }\n",
    "    \n",
    "    return result\n",
    "\n",
    "average_random_tuples = calculate_average_tuples(random_valence_scores)\n",
    "pprint(average_random_tuples)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_order = ['GPT-3.5', 'GPT-3.5(ITA)', 'Haiku', 'Haiku(ITA)', 'Llama-3-8B', 'LLaMAntino-2(ITA)', 'Mistral-7b']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "artificialdictionary={}\n",
    "\n",
    "# Prepare the data for plotting\n",
    "data = []\n",
    "for model in model_order:\n",
    "    for score_type in ['pos_pos', 'pos_neg', 'neg_neg']:\n",
    "        true_score = true_valence_scores[model][score_type]\n",
    "        random_mean, random_std, (ci_low, ci_high) = random_stats[model][score_type]\n",
    "        data.append({\n",
    "            'Model': model,\n",
    "            'Score Type': f\"{score_type}_true\",\n",
    "            'Score': round(true_score),\n",
    "            'CI': None,\n",
    "        })\n",
    "        artificialdictionary[round(random_mean)]=round(random_mean-ci_low)\n",
    "        data.append({\n",
    "            'Model': model,\n",
    "            'Score Type': f\"{score_type}_random\",\n",
    "            'Score': round(random_mean),\n",
    "            'CI': round(random_mean-ci_low),\n",
    "        })\n",
    "\n",
    "#data2 = []\n",
    "#model_order = ['gpt-3.5', 'GPT-3.5(ITA)', 'Haiku', 'Haiku(ITA)', 'Llama-3-8B', 'LLaMAntino-2(ITA)', 'Mistral-7b']\n",
    "#for model in model_order:\n",
    "#    for score_type in ['pos_pos', 'pos_neg', 'neg_neg']:\n",
    "#        data2.append({'Model': model, 'Score Type': f'{score_type}_true', 'Score': true_valence_scores[model][score_type]})\n",
    "#        data2.append({'Model': model, 'Score Type': f'{score_type}_random', 'Score': average_random_tuples[model][score_type]})\n",
    "\n",
    "display(data)\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "display(df)\n",
    "#display(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the plot\n",
    "plt.figure(figsize=(20, 6))\n",
    "sns.set_style(\"whitegrid\", {'grid.linestyle': '--'})\n",
    "\n",
    "# Create a custom color palette\n",
    "colors = ['#2E8B57', '#90EE90', '#4682B4', '#ADD8E6', '#FF6347', '#FFA500']\n",
    "palette = dict(zip(['pos_pos_true', 'pos_pos_random', 'pos_neg_true', 'pos_neg_random', 'neg_neg_true', 'neg_neg_random'], colors))\n",
    "\n",
    "# Reorder the 'Score Type' column\n",
    "order = ['pos_pos_true', 'pos_pos_random', 'pos_neg_true', 'pos_neg_random', 'neg_neg_true', 'neg_neg_random']\n",
    "df['Score Type'] = pd.Categorical(df['Score Type'], categories=order, ordered=True)\n",
    "df = df.sort_values(['Model', 'Score Type'])\n",
    "\n",
    "# Set the order of the models\n",
    "df['Model'] = pd.Categorical(df['Model'], categories=model_order, ordered=True)\n",
    "\n",
    "# Create the grouped barplot\n",
    "ax = sns.barplot(x='Model', y='Score', hue='Score Type', data=df, palette=palette, hue_order=order, order=model_order,\n",
    "                 errcolor='black', capsize=0.05)  # Add errcolor and capsize parameters\n",
    "\n",
    "# Customize the plot\n",
    "plt.title(f'{captiondictionary[folders_of_interest[0]]}: Comparison of structural valence of edges -  True Scores vs Random Scores', fontsize=25, fontweight='bold', pad=20)\n",
    "plt.xlabel(' ', fontsize=1, fontweight='bold', labelpad=1)\n",
    "plt.ylabel('N. Edges', fontsize=18, fontweight='bold', labelpad=15)\n",
    "plt.xticks(rotation=45, ha='right', fontsize=18, fontweight='bold')\n",
    "plt.yticks(fontsize=18)\n",
    "\n",
    "# Modify legend\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "new_labels = ['pos_pos (True)', 'pos_pos (Random)', 'pos_neg (True)', \n",
    "              'pos_neg (Random)', 'neg_neg (True)', 'neg_neg (Random)']\n",
    "plt.legend(handles, new_labels, title='Score Type', title_fontsize='24', fontsize='20', \n",
    "           bbox_to_anchor=(1, 1), loc='upper left', borderaxespad=0)\n",
    "\n",
    "\n",
    "for container in ax.containers:\n",
    "    for i, patch in enumerate(container.patches):\n",
    "            if round(patch.get_height()) in artificialdictionary:\n",
    "                ax.errorbar(x=patch.get_x()+patch.get_width()/2, \n",
    "                    y=patch.get_height(),\n",
    "                    yerr= artificialdictionary[patch.get_height()], fmt='none', ecolor='black', capsize=1, capthick=1,alpha=0.5)\n",
    "\n",
    "#Add value labels on top of the bars\n",
    "#for container in ax.containers:\n",
    "#    ax.bar_label(container, fmt='%.0f', label_type='edge', fontsize=10, fontweight='bold', padding=2)\n",
    "# Adjust layout and display the plot\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Z scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def compute_z_scores(distribution, true_values):\n",
    "    z_scores = {}\n",
    "    for key in true_values.keys():\n",
    "        mean = np.mean([item[key] for item in distribution])\n",
    "        std = np.std([item[key] for item in distribution])\n",
    "        z_scores[key] = (true_values[key] - mean) / std\n",
    "    return z_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for folder in folders_of_interest:\n",
    "    input_folder_path = os.path.join(base_output_dir, folder)\n",
    "    true_folder_path = os.path.join(true_dir, folder)\n",
    "\n",
    "    for filename in os.listdir(input_folder_path):\n",
    "\n",
    "            file_path = os.path.join(input_folder_path, filename)\n",
    "\n",
    "            true_path = os.path.join(true_folder_path, (filename.rstrip('_valence.jsonl')+'.jsonl'))\n",
    "\n",
    "            # get the true values\n",
    "            with open(true_path, 'r') as file:\n",
    "\n",
    "                fmnts=[]\n",
    "                for line in file:\n",
    "                    data = json.loads(line)\n",
    "                    fmnts.append(data['fmnt']['syntactic'])\n",
    "            \n",
    "            w_fmnt=emos.combine_edgelists(fmnts)\n",
    "\n",
    "            if ('ITA') in filename:\n",
    "                truescores= get_true_scores(w_fmnt,language='italian',get_percentage=True)\n",
    "            else:\n",
    "                truescores= get_true_scores(w_fmnt,language='english',get_percentage=True)\n",
    "\n",
    "            results = []\n",
    "            with open(file_path, 'r') as file:\n",
    "                for line in file:\n",
    "                    data = json.loads(line)\n",
    "                    total = data['pos_pos'] + data['pos_neg'] + data['neg_neg']\n",
    "                    results.append({\n",
    "                        'pos_pos_pct': data['pos_pos'] / total * 100,\n",
    "                        'pos_neg_pct': data['pos_neg'] / total * 100,\n",
    "                        'neg_neg_pct': data['neg_neg'] / total * 100\n",
    "                    })\n",
    "            \n",
    "\n",
    "            # Calculate the mean of the random distributions\n",
    "            random_scores ={\n",
    "            'mean_pos_pos_pct' : np.mean([item['pos_pos_pct'] for item in results]),\n",
    "            'mean_pos_neg_pct' : np.mean([item['pos_neg_pct'] for item in results]),\n",
    "            'mean_neg_neg_pct' : np.mean([item['neg_neg_pct'] for item in results])\n",
    "            }\n",
    "           \n",
    "\n",
    "            \n",
    "            z_scores = compute_z_scores(results,truescores)\n",
    "            print(filename.rstrip('_valence.jsonl'))\n",
    "            print('percentage of true scores: ',truescores)\n",
    "            print('average percentage of random scores:',random_scores)\n",
    "            print('zscores: ', z_scores)\n",
    "            print('=====================')\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Emoatlas_0-1-2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
