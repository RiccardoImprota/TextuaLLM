{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from emoatlas import EmoScores\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "from pprint import pprint\n",
    "import pymongo\n",
    "import networkx as nx\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from emoatlas.resources import _valences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the base directory containing the folders of interest\n",
    "base_dir = 'localdb'\n",
    "\n",
    "# Folders of interest\n",
    "folders_of_interest = ['math']\n",
    "model1='Haiku'\n",
    "\n",
    "\n",
    "emos = EmoScores()\n",
    "emosita = EmoScores('italian')\n",
    "\n",
    "language='eng'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_data={}\n",
    "\n",
    "for folder in folders_of_interest:\n",
    "    folder_path = os.path.join(base_dir, folder)\n",
    "\n",
    "    for filename in os.listdir(folder_path):\n",
    "        \n",
    "        fmnts=[]\n",
    "        texts=[]\n",
    "\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        \n",
    "        if language=='ita':\n",
    "            if '(ITA)' in file_path:\n",
    "                with open(file_path, 'r') as file:\n",
    "                    for line in file:\n",
    "                        json_obj = json.loads(line)\n",
    "                        fmnts.append(json_obj['fmnt']['syntactic'])\n",
    "                        texts.append(' '.join(json_obj['lemmatized_test']))\n",
    "                models_data[filename.rstrip('.jsonl')] = { 'Network': emosita.combine_edgelists(fmnts),\n",
    "                                         'Texts': ' '.join(texts)\n",
    "                }              \n",
    "        if language=='eng':\n",
    "            if '(ITA)' not in file_path:\n",
    "                with open(file_path, 'r') as file:\n",
    "                    for line in file:\n",
    "                        json_obj = json.loads(line)\n",
    "                        fmnts.append(json_obj['fmnt']['syntactic'])\n",
    "                        texts.append(' '.join(json_obj['lemmatized_test']))\n",
    "                models_data[filename.rstrip('.jsonl')] = { 'Network': emos.combine_edgelists(fmnts),\n",
    "                                         'Texts': ' '.join(texts)\n",
    "                }              \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(models_data.keys())\n",
    "\n",
    "\n",
    "\n",
    "retenonpesata = [(i[0],i[1]) for i in models_data[model1]['Network']]\n",
    "retepesata = [(i[0],i[1]) for i in models_data[model1]['Network'] if i[2]>49]\n",
    "print(retepesata)\n",
    "\n",
    "\n",
    "# Create a directed graph using networkx\n",
    "G = nx.Graph()\n",
    "G.add_edges_from(retepesata)\n",
    "if \"anxiety\" in G:\n",
    "    degree = G.degree(\"anxiety\")\n",
    "    print(f'The degree of the word \"anxiety\" is: {degree}')\n",
    "else:\n",
    "    print('\"anxiety\" is not in the graph.')\n",
    "\n",
    "Gfm=emos.nxgraph_to_formamentis(G)\n",
    "   \n",
    "fmnt_you = emos.extract_word_from_formamentis(Gfm, 'anxiety')\n",
    "emos.draw_formamentis(fmnt_you,alpha_syntactic=0.4,thickness=0.7)\n",
    "# Therapist\n",
    "# Non presente in Haiku\n",
    "#The max diameter of the network is: 4\n",
    "#The shortest path length to these nodes is: 3\n",
    "\n",
    "# GPT - 3.5:\n",
    "#The max diameter of the network is: 5\n",
    "#The furthest nodes from 'math' are: ['post', 'secondary', 'size', 'therapist']\n",
    "#The shortest path length to these nodes is: 3\n",
    "\n",
    "#Llama-3-8B\n",
    "#The max diameter of the network is: 8\n",
    "#The furthest nodes from 'math' are: ['demetrovics']\n",
    "#The shortest path length to these nodes is: 5\n",
    "\n",
    "#The max diameter of the network is: 9\n",
    "#The furthest nodes from 'math' are: ['finkelstein']\n",
    "#The shortest path length to these nodes is: 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "settone=set()\n",
    "for i in models_data[model1]['Network']:\n",
    "    settone.add(i[0])\n",
    "    settone.add(i[1])\n",
    "print(settone)\n",
    "print('therapist' in settone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "retenonpesata = [(i[0],i[1]) for i in models_data[model1]['Network']]\n",
    "retepesata = [(i[0],i[1]) for i in models_data[model1]['Network'] if i[2]>50]\n",
    "print(retepesata)\n",
    "\n",
    "\n",
    "# Create a directed graph using networkx\n",
    "G = nx.Graph()\n",
    "G.add_edges_from(retepesata)\n",
    "\n",
    "# Finding all the connected components of the graph\n",
    "components = list(nx.connected_components(G))\n",
    "\n",
    "# Calculating the diameter for each connected component\n",
    "diameters = []\n",
    "for component in components:\n",
    "    subgraph = G.subgraph(component)\n",
    "    diameters.append(nx.diameter(subgraph))\n",
    "\n",
    "# The diameter of the graph is the maximum diameter among its connected components\n",
    "max_diameter = max(diameters)\n",
    "\n",
    "def get_furthest_nodes(G, source_node):\n",
    "    # Calculate shortest path lengths from the source node to all other nodes\n",
    "    path_lengths = nx.single_source_shortest_path_length(G, source_node)\n",
    "    \n",
    "    # Find the maximum path length\n",
    "    max_length = max(path_lengths.values())\n",
    "    \n",
    "    # Get all nodes with the maximum path length\n",
    "    furthest_nodes = [node for node, length in path_lengths.items() if length == max_length]\n",
    "    almost_furthest_nodes = [node for node, length in path_lengths.items() if length == max_length-1]\n",
    "    print(f\"The furthest nodes from '{source_node}' are: {almost_furthest_nodes}\")\n",
    "\n",
    "    return furthest_nodes, max_length\n",
    "\n",
    "# Example usage:\n",
    "# Assuming you have a graph G\n",
    "\n",
    "# Find the furthest nodes from \"math\"\n",
    "source_node = \"math\"\n",
    "furthest_nodes, max_length = get_furthest_nodes(G, source_node)\n",
    "\n",
    "print(f\"The max diameter of the network is: {max_diameter}\")\n",
    "print(f\"The furthest nodes from '{source_node}' are: {furthest_nodes}\")\n",
    "print(f\"The shortest path length to these nodes is: {max_length}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retepesatapermindstream = [(i[0],i[1],i[2]) for i in models_data[model1]['Network'] if i[2]>50]\n",
    "\n",
    "settone=set()\n",
    "for i in retepesatapermindstream:\n",
    "    settone.add(i[0])\n",
    "    settone.add(i[1])\n",
    "print(settone)\n",
    "print('therapist' in settone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in retepesatapermindstream:\n",
    "    if i[0]=='therapist' or i[1]=='therapist':\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emos.plot_mindset_stream(retepesatapermindstream,'math','therapist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retenonpesata = [(i[0],i[1]) for i in models_data[model1]['Network']]\n",
    "\n",
    "\n",
    "# Create a directed graph using networkx\n",
    "G = nx.Graph()\n",
    "G.add_edges_from(retenonpesata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Gfm=emos.nxgraph_to_formamentis(G)\n",
    "fmnt_you = emos.extract_word_from_formamentis(Gfm, 'medium')\n",
    "emos.draw_statistically_significant_emotions(fmnt_you,title=f'Emotion detection - Medium, {model1}')\n",
    "fmnt_you = emos.extract_word_from_formamentis(Gfm, 'social')\n",
    "emos.draw_statistically_significant_emotions(fmnt_you,title=f'Emotion detection - Social, {model1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%\\begin{figure}[!htbp]\n",
    "%    \\centering\n",
    "%    \\begin{subfigure}[t]{0.49\\textwidth}\n",
    "%        \\centering\n",
    "%        \\captionsetup{justification=centering}\n",
    "%        \\includegraphics[width=\\linewidth, trim=0.25cm 0.25cm 0.25cm 1.25cm, clip]{figures/mistraltherapist.png}\n",
    "%        \\caption{Math Anxiety - Mindset Stream of \\textsc{\\char13}Math-Therapist\\textsc{\\char13} in the combined TFMN of Mistral. \\textbf{Only the top 0.05\\% quantile of shortest path weights are shown.}}\n",
    "%    \\end{subfigure}\n",
    "%    \\begin{subfigure}[t]{0.49\\textwidth}\n",
    "%        \\centering\n",
    "%        \\captionsetup{justification=centering}\n",
    "%        \\includegraphics[width=\\linewidth, trim=0.25cm 0.25cm 0.25cm 1.25cm, clip]{figures/llamatherapist.png}\n",
    "%        \\caption{Math Anxiety - Mindset Stream of \\textsc{\\char13}Math-Therapist\\textsc{\\char13} in the combined TFMN of LLama. All shortest paths are shown.}\n",
    "%    \\end{subfigure}\n",
    "%    \n",
    "%    \\begin{subfigure}[t]{0.49\\textwidth}\n",
    "%        \\centering\n",
    "%        \\captionsetup{justification=centering}\n",
    "%        \\includegraphics[width=\\linewidth, trim=0.25cm 0.25cm 0.25cm 1.25cm, clip]{figures/mindsettherapist.png}\n",
    "%        {Mindset stream of \\textsc{\\char13}math-therapist\\textsc{\\char13} in the combined TFMN of GPT-3.5. All shortest paths are shown.}\n",
    "%    \\end{subfigure}\n",
    "%    \\caption{{Math Anxiety - Mindset Stream of \\textsc{\\char13}Math-Therapist\\textsc{\\char13} in the combined TFMN of various LLMs.}}\n",
    "%    \\label{fig:mindsetmath}\n",
    "%\\end{figure}\n",
    "%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retepesatafiltrata = [(i[0],i[1],i[2]) for i in models_data[model1]['Network'] if i[2]>=1]\n",
    "retepesatafiltrata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emos.plot_mindset_stream(retepesatafiltrata,'math','therapist',top_quantile=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emos.plot_mindset_stream(retenonpesata,'math','therapist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_path_weight(network, path):\n",
    "    weight = 0\n",
    "    for i in range(len(path) - 1):\n",
    "        for edge in network:\n",
    "            if (edge[0] == path[i] and edge[1] == path[i+1]) or (edge[1] == path[i] and edge[0] == path[i+1]):\n",
    "                weight += edge[2]\n",
    "                break\n",
    "    return weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_paths(network, start_node, end_node):\n",
    "\n",
    "    all_paths = emos.find_all_shortest_paths(network,start_node,end_node)\n",
    "    \n",
    "    path_weights = []\n",
    "    for path in all_paths:\n",
    "        weight = calculate_path_weight(network, path)\n",
    "        path_weights.append((path, weight))\n",
    "    \n",
    "    df = pd.DataFrame(path_weights, columns=['Path', 'Total Weight'])\n",
    "    df['Path'] = df['Path'].astype(str)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_path_weights(df):\n",
    "    # Sort the dataframe by 'Total Weight' in descending order\n",
    "    df_sorted = df.sort_values('Total Weight', ascending=False)\n",
    "\n",
    "    sns.set_style(\"whitegrid\")\n",
    "    # Create the horizontal bar plot\n",
    "    plt.figure(figsize=(10, 12))  # Adjusted figure size for better visibility\n",
    "    ax = sns.barplot(y='Path', x='Total Weight', data=df_sorted, palette='viridis_r', orient='h')\n",
    "\n",
    "    # Customize the plot\n",
    "    plt.title('Total Shortest Path Weights', fontsize=16)\n",
    "    plt.xlabel('Total Path Weight', fontsize=12)\n",
    "    plt.ylabel('Path', fontsize=12)\n",
    "\n",
    "    # Make y-axis labels smaller\n",
    "    plt.yticks(fontsize=8)\n",
    "\n",
    "    # Add value labels at the end of each bar\n",
    "    for i, v in enumerate(df_sorted['Total Weight']):\n",
    "        ax.text(v, i, f' {v}', va='center', fontsize=8)\n",
    "\n",
    "    # Add a line separating the top quartile\n",
    "    n = len(df_sorted)\n",
    "    quartile_index = int(0.25 * n)  # Changed to 0.25 as the order is now descending\n",
    "    quartile_value = df_sorted['Total Weight'].iloc[quartile_index]\n",
    "    plt.axvline(x=quartile_value, color='black', linestyle='--', linewidth=1)\n",
    "\n",
    "    # Add text annotation for the quartile line\n",
    "    plt.text(quartile_value + (quartile_value * 0.2), n-n-1.5, 'Top Quartile', ha='center', va='top', color='black', fontsize=14, rotation=360)\n",
    "\n",
    "    # Adjust layout and show the plot\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = analyze_paths(weighted_network,'human','future')\n",
    "\n",
    "plot_path_weights(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emos.plot_mindset_stream(weighted_network,'human','future')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_quantile_paths(network, start_node, end_node, top_quantile=0.25):\n",
    "    all_paths = emos.find_all_shortest_paths(network, start_node, end_node)\n",
    "    \n",
    "    path_weights = []\n",
    "    for path in all_paths:\n",
    "        weight = calculate_path_weight(network, path)\n",
    "        path_weights.append((path, weight))\n",
    "    \n",
    "    # Sort paths by weight in descending order\n",
    "    sorted_paths = sorted(path_weights, key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # Calculate the number of paths to keep\n",
    "    paths_to_keep = max(1, int(len(sorted_paths) * top_quantile))\n",
    "    \n",
    "    # Return only the paths (not the weights) from the top quantile\n",
    "    return [path for path, _ in sorted_paths[:paths_to_keep]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_paths = get_top_quantile_paths(weighted_network,'human','future')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_unique_words(lists_of_lists):\n",
    "    # Initialize a set to store unique words\n",
    "    unique_words = set()\n",
    "    \n",
    "    # Iterate through each list in the list of lists\n",
    "    for sublist in lists_of_lists:\n",
    "        # Iterate through each word in the sublist\n",
    "        for word in sublist:\n",
    "            # Add the word to the set\n",
    "            unique_words.add(word)\n",
    "    \n",
    "    # Join the unique words into a single string separated by spaces\n",
    "    result_string = ' '.join(unique_words)\n",
    "    emos.draw_formamentis_flower(result_string)\n",
    "    return result_string\n",
    "\n",
    "extract_unique_words(emos.find_all_shortest_paths(weighted_network,'human','future'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emos.plot_mindset_stream(weighted_network,'community','future',shortest_paths=top_paths)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emos.plot_mindset_stream(weighted_network,'human','future')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def path_metrics(weighted_network, start_node, end_node, shortest_paths=None, top_quantile=None):\n",
    "\n",
    "\n",
    "    if shortest_paths == None:\n",
    "            shortest_paths = emos.find_all_shortest_paths(weighted_network, start_node, end_node)\n",
    "    if top_quantile != None and shortest_paths == None:\n",
    "        try:\n",
    "            shortest_paths = emos.get_top_quantile_shortest_paths(\n",
    "                graph, start_node, end_node, top_quantile=top_quantile\n",
    "            )\n",
    "        except:\n",
    "            raise ValueError(\n",
    "                \"If a quantile is set, weights should be necessary in the graph.\"\n",
    "            )\n",
    "\n",
    "    positive, negative, ambivalent = _valences('english')\n",
    "\n",
    "    def get_valence(word):\n",
    "        if word in positive:\n",
    "            return 'positive'\n",
    "        elif word in negative:\n",
    "            return 'negative'\n",
    "        else:\n",
    "            return 'neutral'\n",
    "    \n",
    "    print(get_valence('change'))\n",
    "\n",
    "    # Unweighted network analysis\n",
    "    positive_edges = 0\n",
    "    negative_edges = 0\n",
    "    all_positive_paths = 0\n",
    "    all_negative_paths = 0\n",
    "    all_neutral_paths = 0\n",
    "\n",
    "    for path in shortest_paths:\n",
    "        valences = [get_valence(word) for word in path]\n",
    "        \n",
    "        # Count edges\n",
    "        for i in range(len(path) - 1):\n",
    "            if valences[i] == 'positive' and valences[i+1] == 'positive':\n",
    "                positive_edges += 1\n",
    "            elif valences[i] == 'negative' and valences[i+1] == 'negative':\n",
    "                negative_edges += 1\n",
    "        \n",
    "        # Count paths\n",
    "        if all(v == 'positive' for v in valences):\n",
    "            all_positive_paths += 1\n",
    "        elif all(v == 'negative' for v in valences):\n",
    "            all_negative_paths += 1\n",
    "        elif all(v == 'neutral' for v in valences):\n",
    "            all_neutral_paths += 1\n",
    "\n",
    "    print(\"Unweighted Network Metrics:\")\n",
    "    print(f\"Edges connecting 2 positive nodes: {positive_edges}\")\n",
    "    print(f\"Edges connecting 2 negative nodes: {negative_edges}\")\n",
    "    print(f\"Paths where all words are positive: {all_positive_paths}\")\n",
    "    print(f\"Paths where all words are negative: {all_negative_paths}\")\n",
    "    print(f\"Paths where all words are neutral: {all_neutral_paths}\")\n",
    "\n",
    "    # Weighted network analysis\n",
    "    weight_pos_pos = 0\n",
    "    weight_pos_neutral = 0\n",
    "    weight_neg_neutral = 0\n",
    "    weight_neg_neg = 0\n",
    "    weight_neutral_neutral = 0\n",
    "\n",
    "    for node1, node2, weight in weighted_network:\n",
    "        valence1 = get_valence(node1)\n",
    "        valence2 = get_valence(node2)\n",
    "        \n",
    "        if valence1 == 'positive' and valence2 == 'positive':\n",
    "            weight_pos_pos += weight\n",
    "        elif (valence1 == 'positive' and valence2 == 'neutral') or (valence1 == 'neutral' and valence2 == 'positive'):\n",
    "            weight_pos_neutral += weight\n",
    "        elif (valence1 == 'negative' and valence2 == 'neutral') or (valence1 == 'neutral' and valence2 == 'negative'):\n",
    "            weight_neg_neutral += weight\n",
    "        elif valence1 == 'negative' and valence2 == 'negative':\n",
    "            weight_neg_neg += weight\n",
    "        elif valence1 == 'neutral' and valence2 == 'neutral':\n",
    "            weight_neutral_neutral += weight\n",
    "\n",
    "    print(\"\\nWeighted Network Metrics:\")\n",
    "    print(f\"Total weight of edges between positive nodes: {weight_pos_pos}\")\n",
    "    print(f\"Total weight of edges between positive and neutral nodes: {weight_pos_neutral}\")\n",
    "    print(f\"Total weight of edges between positive and neutral nodes: {weight_neg_neutral}\")\n",
    "    print(f\"Total weight of edges between negative nodes: {weight_neg_neg}\")\n",
    "    print(f\"Total weight of edges between neutral nodes: {weight_neutral_neutral}\")\n",
    "\n",
    "    # Plotting\n",
    "    labels = ['Positive-Positive', 'Positive-Neutral','Negative-Neutral', 'Negative-Negative', 'Neutral-Neutral']\n",
    "    sizes = [weight_pos_pos, weight_pos_neutral,weight_neg_neutral, weight_neg_neg, weight_neutral_neutral]\n",
    "    plt.pie(sizes, labels=labels, autopct='%1.1f%%', startangle=90)\n",
    "    plt.axis('equal')\n",
    "    plt.title('Distribution of Edge Weights by Node Valence')\n",
    "    plt.show()\n",
    "\n",
    "# Example usage:\n",
    "\n",
    "path_metrics(weighted_network,'human','future')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Emoatlas_0-1-2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
